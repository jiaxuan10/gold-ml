#!/usr/bin/env python3
# src/live/realtime_fetcher.py

import os
import time
import sys
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta, timezone
import warnings

warnings.simplefilter(action='ignore', category=FutureWarning)

# Path Setup
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(os.path.join(ROOT, "src"))

# Import Unified Feature Engineering
from features.features_engineering import add_technical_features

OUT_DIR = os.path.join(ROOT, "data", "final")
os.makedirs(OUT_DIR, exist_ok=True)
OUTPUT_CSV = os.path.join(OUT_DIR, "latest_hour_features.csv")

ASSETS = {
    "GOLD": "GC=F",
    "DXY": "DX-Y.NYB",
    "SP500": "^GSPC",
    "NASDAQ": "^IXIC",
    "VIX": "^VIX",
    "BTCUSD": "BTC-USD",
    "ETHUSD": "ETH-USD",
}

HIST_WINDOW = 720  # Need enough history for SMA_60 and Volatility
CHECK_INTERVAL = 300 # Fetch every 5 minutes

def fetch_latest_window():
    end_date = datetime.now(timezone.utc)
    start_date = end_date - timedelta(hours=HIST_WINDOW)

    print(f"ğŸ“¡ Connecting to Yahoo Finance... ({datetime.now().strftime('%H:%M:%S')})")
    df = yf.download(
        tickers=list(ASSETS.values()),
        start=start_date,
        end=end_date,
        interval="1h",
        auto_adjust=True,
        progress=False,
        threads=True,
    )

    if df is None or df.empty:
        print("âŒ No data returned.")
        return None

    # Fix MultiIndex
    if isinstance(df.columns, pd.MultiIndex):
        df = df.swaplevel(0, 1, axis=1)
        df.sort_index(axis=1, level=0, inplace=True)

    # Extract Gold
    if "GC=F" not in df.columns.levels[0]:
        return None

    gold_df = df["GC=F"].copy().reset_index()
    
    # Rename standard columns
    merged = gold_df.rename(columns={
        "Datetime": "Date", "Date": "Date",
        "Close": "GOLD_Close", "Open": "GOLD_Open", 
        "High": "GOLD_High", "Low": "GOLD_Low", "Volume": "GOLD_Volume"
    })
    
    # Merge other assets
    for sym in ASSETS.values():
        if sym == "GC=F": continue
        if sym in df.columns.levels[0]:
            sub = df[sym][["Close"]].reset_index().rename(columns={"Datetime": "Date", "Close": sym})
            merged = pd.merge_asof(merged.sort_values("Date"), sub.sort_values("Date"), on="Date")

    # 1. å…ˆå¡«å…… (ffill) 
    # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†é˜²æ­¢å› ä¸ºæŸäº›èµ„äº§å¶å°”ç¼ºæ•°æ®å¯¼è‡´ NaN
    merged = merged.ffill().bfill()

    # âœ… å…³é”®é€»è¾‘ä¸€ï¼šç¡®ä¿æ—¶é—´æ ¼å¼å¹¶å‰”é™¤å‘¨å…­ (Closed Market)
    # 0=Mon, 4=Fri, 5=Sat(ä¼‘å¸‚), 6=Sun(æ™šä¸Šå¼€å¸‚)
    merged["Date"] = pd.to_datetime(merged["Date"], utc=True)
    merged = merged[merged["Date"].dt.dayofweek != 5].reset_index(drop=True)

    # âœ… å…³é”®é€»è¾‘äºŒï¼šå‰”é™¤â€œåƒµå°¸æ•°æ®â€ (Flat Line Cleaner)
    # å¦‚æœ Close ä»·æ ¼è·Ÿä¸Šä¸€è¡Œå®Œå…¨ä¸€æ ·ï¼Œè¯´æ˜è¿™æ˜¯ ffill åˆ¶é€ çš„å‡æ•°æ®ï¼ˆä¾‹å¦‚å‡æœŸä¼‘å¸‚ï¼‰
    # diff() è®¡ç®—å·®å€¼ï¼Œabs() å–ç»å¯¹å€¼ï¼Œ> 1e-6 æ„å‘³ç€â€œåªè¦æœ‰æå¾®å°çš„å˜åŠ¨å°±ä¿ç•™â€
    # fillna(1.0) æ˜¯ä¸ºäº†ä¿æŠ¤ç¬¬ä¸€è¡Œä¸è¢«åˆ æ‰
    if "GOLD_Close" in merged.columns:
        merged = merged[merged["GOLD_Close"].diff().fillna(1.0).abs() > 1e-6].reset_index(drop=True)

    # âœ… å…³é”®é€»è¾‘ä¸‰ï¼šå‰”é™¤â€œæœªå®Œæˆâ€çš„æœ€æ–° K çº¿ (Unfinished Candle Logic)
    # åªæœ‰å½“ K çº¿æ—¶é—´ < å½“å‰æ—¶é—´ (å³å·²ç»è¿‡å»çš„å®Œæ•´å°æ—¶) æ‰ä¿ç•™
    if not merged.empty:
        current_utc_hour = datetime.now(timezone.utc).replace(minute=0, second=0, microsecond=0)
        last_row_time = merged["Date"].iloc[-1]
        
        if last_row_time >= current_utc_hour:
            print(f"âœ‚ï¸ Dropping unfinished candle: {last_row_time} (Current UTC: {current_utc_hour})")
            merged = merged.iloc[:-1]

    # 2. ç„¶åå†è®¡ç®—æŒ‡æ ‡ (æ­¤æ—¶æ•°æ®åœ¨æ—¶é—´ä¸Šæ˜¯â€œæ— ç¼æ‹¼æ¥â€ä¸”â€œå®Œæ•´â€çš„)
    merged = add_technical_features(merged)
    
    # Trim to save space (keep last 200 rows is enough for inference)
    return merged.tail(200)

if __name__ == "__main__":
    print(f"ğŸ”„ Realtime Fetcher Started. Saving to {OUTPUT_CSV}")
    while True:
        try:
            data = fetch_latest_window()
            if data is not None and not data.empty:
                data.to_csv(OUTPUT_CSV, index=False)
                print(f"âœ… Data Updated. Last Candle Used: {data['Date'].iloc[-1]}")
            else:
                print("âš ï¸ Fetch failed or empty.")
        except Exception as e:
            print(f"âš ï¸ Error: {e}")
        
        time.sleep(CHECK_INTERVAL)