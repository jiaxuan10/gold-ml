#!/usr/bin/env python3
"""
simulate_trading.py
-------------------------------------------------
Backtesting entry for Profit-Boost v6 with correct feature engineering.
âœ… Saves metrics to JSON for Dashboard integration.
"""

import os
import sys
import pickle
import json  # <--- âœ… 1. å¯¼å…¥ json
import pandas as pd
import numpy as np
from datetime import datetime

# --- make sure src is in path to import features ---
ROOT_SRC = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.append(ROOT_SRC)

from features.features_engineering import add_technical_features
from strategy import ProfitBoostStrategy

ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
# æ³¨æ„ï¼šè¿™æ˜¯ä½ è´´å‡ºæ¥çš„ä»£ç é‡Œçš„ç¡¬ç¼–ç è·¯å¾„ã€‚å¦‚æžœä½ æƒ³è‡ªåŠ¨åŠ è½½æœ€æ–°çš„ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚
MODEL_PATH = os.path.join(ROOT, "models", "run_20251204_015416", "ensemble_calibrated_20251204_015416.pkl")
DATA_PATH = os.path.join(ROOT, "data", "final", "final_dataset_hourly.csv")
SAVE_DIR = os.path.join(ROOT, "backtest_results")
os.makedirs(SAVE_DIR, exist_ok=True)


def main():
    # --- Load dataset ---
    if not os.path.exists(DATA_PATH):
        print("Data not found:", DATA_PATH)
        return

    df = pd.read_csv(DATA_PATH)
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    df = df.dropna(subset=["Date"]).sort_values("Date").reset_index(drop=True)
    print(f"Loaded dataset: {len(df)} rows, {df['Date'].min()} â†’ {df['Date'].max()}")

    # --- Load model ---
    if not os.path.exists(MODEL_PATH):
        print("Model not found:", MODEL_PATH)
        return

    with open(MODEL_PATH, "rb") as f:
        model_meta = pickle.load(f)
    print("Loaded model:", MODEL_PATH)

    # --- Rename columns to match training ---
    rename_map = {
        "GOLD_Close": "Close",
        "GOLD_Open": "Open",
        "GOLD_High": "High",
        "GOLD_Low": "Low",
        "GOLD_Volume": "Volume"
    }
    df = df.rename(columns=rename_map)

    # --- Feature engineering ---
    df = add_technical_features(df)

    # --- Feature alignment ---
    feature_cols = model_meta.get("feature_cols", [])
    if not feature_cols:
        print("âš ï¸ Warning: no feature_cols found in model_meta.")

    # Add missing columns
    for c in feature_cols:
        if c not in df.columns:
            df[c] = np.nan

    # Ensure order + fillna
    X_backtest = df[feature_cols].fillna(df[feature_cols].median())

    # ===== FEATURE DEBUG =====
    print("\n================ FEATURE DEBUG ================")
    print("\nðŸ“Œ Training feature columns:")
    for f in feature_cols:
        print(" -", f)
    print("\n================================================\n")

    # --- Run backtest ---
    strat = ProfitBoostStrategy(model_meta, SAVE_DIR, shift_features=True)
    metrics = strat.simulate(df)

    print("\nBacktest metrics (v6.6):")
    for k, v in metrics.items():
        print(f"{k:20s}: {v}")

    # --- âœ… 2. Save Metrics to JSON ---
    # ä¿å­˜ä¸€ä¸ªå›ºå®šçš„æ–‡ä»¶åï¼Œæ–¹ä¾¿ app.py è¯»å–æœ€æ–°çš„
    latest_metrics_path = os.path.join(SAVE_DIR, "latest_backtest_metrics.json")
    
    # åŒæ—¶ä¹Ÿä¿å­˜ä¸€ä¸ªå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½ï¼Œç”¨äºŽè®°å½•
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    history_metrics_path = os.path.join(SAVE_DIR, f"metrics_{ts}.json")

    with open(latest_metrics_path, "w") as f:
        json.dump(metrics, f, indent=4)
        
    with open(history_metrics_path, "w") as f:
        json.dump(metrics, f, indent=4)

    print(f"\nðŸ’¾ Metrics saved to JSON: {latest_metrics_path}")


if __name__ == "__main__":
    main()